{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW05: Predictive Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell if you need to install the PyTorch or Transformers libraries on a lab computer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #!pip install diffusers transformers accelerate safetensors torchvision --upgrade\n",
    " #!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124 --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code imports the libraries we need to run our inference pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from transformers import pipeline\n",
    "from transformers import DetrImageProcessor, DetrForObjectDetection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth [Prediction](https://huggingface.co/depth-anything/Depth-Anything-V2-Base-hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_estimator = pipeline(\n",
    "  task=\"depth-estimation\",\n",
    "  model=\"depth-anything/Depth-Anything-V2-Base-hf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"./imgs/flowers.jpg\")\n",
    "result = depth_estimator(image)\n",
    "display(result[\"depth\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object [Detection](https://huggingface.co/facebook/detr-resnet-101)\n",
    "\n",
    "Some models don't work with the pipeline inference object, but the Transformers library still has some consistent-ish interfaces for running these models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBJ_MODEL = \"facebook/detr-resnet-101\"\n",
    "detr_processor = DetrImageProcessor.from_pretrained(OBJ_MODEL)\n",
    "detr_model = DetrForObjectDetection.from_pretrained(OBJ_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"./imgs/people.jpg\")\n",
    "iw, ih = image.size\n",
    "\n",
    "detr_inputs = detr_processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "detr_output = detr_model(**detr_inputs)\n",
    "detr_results = detr_processor.post_process_object_detection(detr_output, 0.99, [(ih, iw)])\n",
    "\n",
    "display(detr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn label ids into labels\n",
    "for label_id in detr_results[0][\"labels\"]:\n",
    "  print(detr_model.config.id2label[int(label_id)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purchase categorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = {\n",
    "\n",
    "0: \"Utilities\",\n",
    "1: \"Health\",\n",
    "2: \"Dining\",\n",
    "3: \"Travel\",\n",
    "4: \"Education\",\n",
    "5: \"Subscription\",\n",
    "6: \"Family\",\n",
    "7: \"Food\",\n",
    "8: \"Festivals\",\n",
    "9: \"Culture\",\n",
    "10: \"Apparel\",\n",
    "11: \"Transportation\",\n",
    "12: \"Investment\",\n",
    "13: \"Shopping\",\n",
    "14: \"Groceries\",\n",
    "15: \"Documents\",\n",
    "16: \"Grooming\",\n",
    "17: \"Entertainment\",\n",
    "18: \"Social Life\",\n",
    "19: \"Beauty\",\n",
    "20: \"Rent\",\n",
    "21: \"Money transfer\",\n",
    "22: \"Salary\",\n",
    "23: \"Tourism\",\n",
    "24: \"Household\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Load the model\n",
    "model_name = \"kuro-08/bert-transaction-categorization\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample transaction description\n",
    "transaction = \"Transaction: YOUR INPUT HERE\"\n",
    "inputs = tokenizer(transaction, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "\n",
    "# Predict the category\n",
    "outputs = model(**inputs)\n",
    "logits = outputs.logits\n",
    "predicted_category = logits.argmax(-1).item()\n",
    "\n",
    "print(f\"Predicted category: {predicted_category}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
